<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:content="http://purl.org/rss/1.0/modules/content/">
    <channel>
        <title>benmccormick.org</title>
        <description>A blog by Ben McCormick</description>
        <link>http://benmccormick.org</link>
        <lastBuildDate>Sun, 28 May 2017 04:12:21 GMT</lastBuildDate>
        <docs>http://blogs.law.harvard.edu/tech/rss</docs>
        <copyright>All rights reserved 2016, Ben McCormick</copyright>
        <generator>Feed for Node.js</generator>
        <item>
            <title><![CDATA[Mariana Syntax Theme For Atom]]></title>
            <link>https://benmccormick.org/2017/05/28/mariana-syntax-atom/</link>
            <guid>https://benmccormick.org/2017/05/28/mariana-syntax-atom/</guid>
            <pubDate>Sun, 28 May 2017 04:05:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I’ve been using <a href="https://atom.io">Atom</a> as my primary text editor for a year and a half now, but I still occasionally play with other editors and keep up with their updates.  There are a crazy number of good cross platform editors these days, and they all have a bunch of good ideas that get shared and remixed across each other. This week Sublime Text came out with a new release <a href="https://www.sublimetext.com/3dev">Dev Build 3132</a> that included 3 new color schemes.  One of them was Mariana, which I believe is a variation on the also great <a href="http://labs.voronianski.com/oceanic-next-color-scheme/">Oceanic Next</a>, with possibly some influences from my previous favorite dark theme <a href="https://github.com/chriskempson/tomorrow-theme">Tommorrow Night Eighties</a> [^1].  It stood out to me right away.</p>
<div>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">The Mariana syntax theme that shipped in the new Sublime Text is really nice <a href="https://t.co/xbmjBTNoWY">pic.twitter.com/xbmjBTNoWY</a></p>&mdash; Ben McCormick (@ben336) <a href="https://twitter.com/ben336/status/868160533345841152">May 26, 2017</a></blockquote>
</div>
<p>Since I’m no longer using Sublime, I decided to port the theme to Atom.  I built on the work of the great <a href="https://github.com/atom-material/atom-material-syntax">atom-material-syntax</a> package to build out a new theme.  It turns out to be surprisingly easy to build a color scheme in Atom.  Fork an existing theme, change some colors and the details in package.json, delete a bunch of git tags [^2], and then run <code>apm deploy minor</code>, and you’re in business.</p>
<p>You can now download <a href="https://atom.io/themes/mariana-syntax">mariana-syntax</a> in Atom.  This was a quick port.  I’ll be working to optimize it for the languages I use (JS, Python, CSS/Less, HTML and Markdown) over the next few weeks.  I would love to see pull requests for other languages or for anything that I’ve missed so far.  I look forward to this just getting better and better.</p>
<p><img alt="screenshot of mariana-syntax" src="http://benmccormick.org/posts/images/mariana/screenshot.png"
class="full-width"></p>
<p>[^1]: To be clear, I’m not sure how great of an influence this was.  The scheme definitely bears a strong resemblance to both of those color schemes, and the release notes credit both authors as inspiration for the 3 new syntax-themes without naming specific schemes.</p>
<p>[^2]: This Stack Overflow article was helpful <a href="https://stackoverflow.com/a/15755041/1424361">https://stackoverflow.com/a/15755041/1424361</a></p>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
        <item>
            <title><![CDATA[Building Normal Distribution Charts using Highcharts]]></title>
            <link>https://benmccormick.org/2017/05/11/building-normal-curves-highcharts/</link>
            <guid>https://benmccormick.org/2017/05/11/building-normal-curves-highcharts/</guid>
            <pubDate>Fri, 12 May 2017 02:30:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>This week I got to have a little fun remembering some High School math, and using one of my favorite libraries: <a href="https://www.highcharts.com/">Highcharts</a>.  Highcharts is a commercial JavaScript data-viz library, and it makes most standard charts and graphs a breeze to implement.  I was using it to plot a normal distribution in order to display a 95% confidence interval.  It’s a pretty straightforward problem, but its a nice example of a practical use of Highcharts, and comes with a little stats math that many of us may have learned and forgotten.</p>
<h3>The Problem</h3>
<p>The goal was to display a <a href="https://en.wikipedia.org/wiki/Normal_distribution">normal distribution</a> to represent a 95% confidence interval, given the upper and lower bounds of the confidence interval.  A normal distribution is the classic bell curve, where the area under any section of the graph represents the probability that the true value of the measure being tracked is within that range.  These curves are usually represented something like this:</p>
<p><img src="http://benmccormick.org/posts/images/normal-curve/confidence-interval.png" alt="Normal Distribution image"></p>
<p>The x axis of the curve represents the range of values, while the y axis is a function of x that shows the relative probability for different areas.  Data sets that are normally distributed conform to the above bell curve and the <a href="https://en.wikipedia.org/wiki/68%E2%80%9395%E2%80%9399.7_rule">68-95-99.7 rule</a>. There’s a 68% chance that the true value is within 1 standard deviation of the middle of the curve (the mean), a 95% chance that the true value is within 2 standard deviations, and a 99.7% chance that the true value is within 3 standard deviations.</p>
<h3>Step 1: Generating a Dataset</h3>
<p>Highcharts operates by plotting a set of data points, not by handling equations directly.  So our first step is computing a set of data points to plot.  We can find the equation for calculating a normal distribution’s probability density on <a href="https://en.wikipedia.org/wiki/Normal_distribution">Wikipedia</a>.</p>
<p><img src="http://benmccormick.org/posts/images/normal-curve/equation.png" alt="Normal Distribution equation"></p>
<p>Yep, we get to play with an equation that has both π and e in it.  I hope this feels sufficiently like a high school math class now.  But we can actually choose to drop the left side of the equation.  It is the <a href="https://en.wikipedia.org/wiki/Normalizing_constant">normalization constant</a> for the equation: it ensures that the total area under the curve equals 1, but doesn’t change the shape of the curve.  Since we’re simply displaying the shape of the graph and care primarily about showing the range along the x axis, we can ignore it and instead use this function:</p>
<pre><code class="language-javascript">const normalY = (x, mean, stdDev) =&gt; Math.exp((-0.5) * Math.pow((x - mean) / stdDev, 2));
</code></pre>
<p>That’s a good start, but right now we only have an upper and lower bound value for a 95% confidence interval.  So before we can apply the equation, we need to find a mean, a standard deviation, and a set of x values to run the formula against.  The mean and standard deviation are fairly straightforward, and we can use lodash to generate a set of points.  For the sake of this example, we’ll plan on generating 100 points ranging from +/- 5 standard deviations from the mean, which should allow us to see all meaningful parts of the distribution, and still have a bit of padding.</p>
<pre><code class="language-javascript">const getMean = (lowerBound, upperBound) =&gt; (upperBound + lowerBound) / 2;

// distance between mean and each bound of a 95% confidence interval 
// is 2 stdDeviation, so distance between the bounds is 4
const getStdDeviation = (lowerBound, upperBound) =&gt; (upperBound - lowerBound) / 4;


const generatePoints = (lowerBound, upperBound) =&gt; {
  let stdDev = getStdDeviation(lowerBound, upperBound); 
  let min = lowerBound - 2 * stdDev;
  let max = upperBound + 2 * stdDev;
  let unit = max - min / 100;
  return _.range(min, max, unit);
}
</code></pre>
<p>Now that we have the x axis locations for the points, we can generate a whole data series.</p>
<pre><code class="language-javascript">let mean = getMean(lowerBound, upperBound);
let stdDev = getStdDeviation(lowerBound, upperBound);
let points = generatePoints(lowerBound, upperBound);


let seriesData = points.map(x =&gt; ({ x, y: normalY(x, mean, stdDev)}));
</code></pre>
<h3>Step 2: Creating the Chart</h3>
<p>Now we have what we need to generate a chart!  Given the data, It’s easy to make a simple normal distribution curve with highcharts.  All we need to do is create a <code>&lt;div id=&quot;container&quot;&gt;</code> element and then run this JavaScript:</p>
<pre><code class="language-javascript">Highcharts.chart('container', {
    chart: {
        type: 'area'
    },
    series: [{
        data: seriesData,
    }],
});
</code></pre>
<p>Which produces the following graph:</p>
<iframe width="100%" height="400" src="http://benmccormick.org//jsfiddle.net/ben336/8bgm1m18/embedded/result,js/"
allowfullscreen="allowfullscreen" frameborder="0"></iframe>
<p>Thats a good start, but contains a lot of “stuff” that Highcharts provides by default that we don’t necessarily want for our normal distribution illustration.  Let’s cut the title, legend, y-axis, and tooltips/mouse action.  To do that we need a bit more configuration:</p>
<pre><code class="language-javascript">Highcharts.chart('container', {
    chart: {
        type: 'area',
        height: 300,
    },
    title: {
        text: ''
    },
    yAxis: {
      labels: {
        enabled: false,   
      },
      gridLineWidth: 0,
      title: ''
    },
    tooltip: {
       enabled: false,
    },
    legend: {
      enabled: false,
    },
    series: [{
        data: seriesData,
    }],
    plotOptions: {
      area: {
        enableMouseTracking: false,
      }
    }
});
</code></pre>
<iframe width="100%" height="400" src="http://benmccormick.org//jsfiddle.net/ben336/w7165m2u/embedded/result,js/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>
<p>This is pretty great, but we still want to show our confidence interval like the wikipedia image at the top.  Ideally we’d only be filling in the areas within the 95% curve.  Thats pretty easy to do with Highcharts.  We can use <em>zones</em>, Highcharts way of applying different styles to different sections of the chart.  We want our zones to apply to the x axis, and we’ll define 3 zones: 0 to the lower bound, lower bound to the upper bound, and everything else.  In Highcharts that looks like this:</p>
<pre><code class="language-javascript">{
  plotOptions: {
    area: {
      zones: [{
        //fillColor gets the inside of the graph, color would change the lines
        fillColor: 'white',
        // everything below this value has this style applied to it
        value: lowerBound,
      },{
        value: upperBound,
      },{
        fillColor: 'white',
      }]
    },
  },
}
</code></pre>
<p>We also want to show a 95% label on the graph like the image at the start.  There are multiple ways to do that in Highcharts, but for this simple case we’ll just abuse the title attribute and move it down into the middle of the chart:</p>
<pre><code class="language-javascript">{
    title: {
        text: '95%',
        y: 200,
    },
}
</code></pre>
<iframe width="100%" height="400" src="http://benmccormick.org//jsfiddle.net/ben336/81kb997x/embedded/result,js/" allowfullscreen="allowfullscreen" frameborder="0"></iframe>
<p>And with that we’ve taken our original inputs and produced a dynamic illustration of a confidence interval that matches the image we started with.</p>
<h3>More Resources</h3>
<ul>
<li>
<p>Highcharts has great <a href="http://api.highcharts.com/highcharts/">documentation</a> and you can see more <a href="https://www.highcharts.com/demo">demos</a> on their site, both for Highcharts and their stock and map chart variants.  Note that Highcharts is not free for commercial use.  I’ve found that it is well worth the money though for any team that is going to be doing many data visualizations, especially if its using relatively standard forms of data visualizations on variable data.</p>
</li>
<li>
<p>If you need more freeform visualizations, <a href="https://d3js.org/">d3</a> is a great place to look.  Here’s an example of D3 being used to draw a similar chart: <a href="http://bl.ocks.org/phil-pedruco/88cb8a51cdce45f13c7e">http://bl.ocks.org/phil-pedruco/88cb8a51cdce45f13c7e</a>  It’s more involved than the Highcharts example, but allows for more flexibility as a result.  And unlike Highcharts, its free to use for anything.</p>
</li>
</ul>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
        <item>
            <title><![CDATA[Grading Applications on Config Portability]]></title>
            <link>https://benmccormick.org/2017/04/14/grading-applications-on-config-portability/</link>
            <guid>https://benmccormick.org/2017/04/14/grading-applications-on-config-portability/</guid>
            <pubDate>Fri, 14 Apr 2017 21:30:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>This week I got a new laptop, and for the first time in a while I have separate work and personal computers.  One thing that this has made clear to me is that it is still non-trivial to keep settings and configurations easily up to date between 2 different PCs.</p>
<p>In my experience there are several levels of “portability” for applications, which are easy to think of as letter grades.</p>
<h4>A - <em>Seamless</em></h4>
<p>These applications have built in mechanisms for syncing configs and or data between 2 different environments.  When something is updated on one machine, it is either immediately updated on the other, or easy to pull, without having to remember to update anything or doing any previous setup.</p>
<h4>B - <em>Easy</em></h4>
<p>B grade applications are similar to seamless applications, but may have a few more potholes.  Possibly there is some involved setup required to get syncing working initially, or some small chunks of the application configuration don’t sync.</p>
<h4>C - <em>Workable</em></h4>
<p>At this point we’ve moved out of the range of easy syncing solutions.  Here it may be possible to import and export settings from a file, without any automatic syncing.  Or there may be a straightforward way to automate the setup, but no declarative representation of the config state.</p>
<h4>D - <em>Hard</em></h4>
<p>For some applications there is no clear way to sync or import state, but it is probably still possible through scripting if you’re willing to commit to it.</p>
<h4>F - <em>Impossible</em></h4>
<p>Some applications have proprietary settings that can’t be exported or scripted. There is no meaningful way to share settings for these programs.</p>
<h2>A mixed bag</h2>
<p>Setting up my new laptop this week, I found that the software I use a lot was all over the map on this scale.  Here are the grades:</p>
<h4>Atom - <em>B</em></h4>
<img src="http://benmccormick.org/posts/images/portability/atom.jpg" alt ="Atom Logo">
<p><a href="https://atom.io/">Atom</a> doesn’t have native syncing persay (though most configs are in a ~/.atom folder that can possibly be synced with git).  But it has a very nice <a href="https://github.com/atom-community/sync-settings">sync-settings</a> plugin that uses gists to sync settings across multiple machines.  It loses points due to a little bit of upfront pain (when setting up a new machine you need to either create a new gist or find your old one, and you need to generate github auth keys for each instance), but gains them back with a very nice set of options to selectively restore or choose when to backup, and painless support for all of Atom’s 3rd party plugiuns</p>
<h4>Sublime Text - <em>B+</em></h4>
<p><img src="http://benmccormick.org/posts/images/portability/sublime.png" alt="Sublime Logo"></p>
<p><a href="https://www.sublimetext.com/3">Sublime Text</a> saves all of its configurations as JSON, so its pretty easy to move them over.  It loses a few points though for making you figure out how to sync them, and a few more points for sticking user configs by default in the <code>~/Library/Application Support/</code> directory, where it is a bit more difficult to sync using things like git and dotfiles.</p>
<h4>Command Line programs - <em>A-</em></h4>
<div class="img-group">
  <image alt="Vim logo" src="http://benmccormick.org/posts/images/portability/vim.png">
  <image alt="fish logo" src="http://benmccormick.org/posts/images/portability/fish.png">
</div>
<div class="img-group">
  <image alt="git logo" src="http://benmccormick.org/posts/images/portability/git.png">
</div>
<p>Command line programs like Vim, Ack, bash/zsh/fish, and git all nail the idea of declarative configuration files that are stored in a common place.  They fall short of a pure A since they don’t provide a sync solution themselves (that would be very non-unixy), but since it is easy to set up <a href="https://dotfiles.github.io/">dotfile repos</a> to sync and backup these settings, they qualify for a strong A-.</p>
<h4>iTerm2 - <em>C</em></h4>
<p><img src="http://benmccormick.org/posts/images/portability/iterm.png" alt="iterm2 Logo"></p>
<p><a href="https://www.iterm2.com/">iterm2</a> is probably the most popular terminal replacement on the mac.  It has tons of settings that you normally edit through a GUI menu.  It does allow you to export those settings, and import them on another machine.  So you need to have access to the original file to generate a snapshot at any given time and need a way to transfer the file(s), but otherwise this is still pretty workable.</p>
<h4>Hyper - <em>A-</em></h4>
<p><img src="http://benmccormick.org/posts/images/portability/hyper.gif" alt="hyper Logo"></p>
<p><a href="https://hyper.is/">Hyper</a> is a newer <a href="https://electron.atom.io/">Electron</a>-based terminal application for OSX.  Like Sublime Text, it defaults to offering a GUI interface into text based configuration files.  Unlike Sublime Text, it stores that file and its plugin files in the users home directory where they can easily be included in a dotfile repo.</p>
<h4>MacOS - <em>D-</em></h4>
<p><img src="http://benmccormick.org/posts/images/portability/macos.jpg" alt="macOS sierra Logo"></p>
<p>Unlike most of the applications I run on it, MacOS is extremely unfriendly to syncing configurations.  There are a few settings I want the same on all my laptops.  Touchpad scrolling should be in the “unnatural”[^1] direction, keys should repeat when held, and caps log should be disabled/mapped to control.  There is a set of apps that I would always want to have installed.  There is no declarative way to configure this, or sync it across computers.  Apple’s preferred strategy seems to be having folks use time machine backups, which is great for setting up a new computer for the same purpose as an old one when it is being replaced, but unhelpful when 2 laptops are being used by the same person for different purposes.  It is possible to script the setup of a new laptop with scripts like <a href="https://github.com/mathiasbynens/dotfiles/blob/master/.macos">this one</a> but its very involved and when you update a setting the “normal MacOS way”, its not always clear how you would add that setting to a script.  Plus a “from scratch” script won’t help keep 2 machines aligned as their configs diverge over time.</p>
<h4>Cloud Services - <em>A</em></h4>
<div class="img-group">
  <image alt="dropbox" src="http://benmccormick.org/posts/images/portability/dropbox.png">
  <image alt="bear logo" src="http://benmccormick.org/posts/images/portability/bear.png">
</div>
<p>Unsurprisingly, the one class of software that really nails this experience is cloud software.  For services like Dropbox, Bear, Evernote, Slack, email &amp; calendar clients, etc, most if not all settings and data is stored on servers somewhere else, so getting a new machine up to date and staying in sync over time is just a matter of entering a password.  There are reasons to dislike cloud services, but when moving to a new machine, they’re a thing of beauty.</p>
<h2>Takeaways</h2>
<p>If you are going to be using 2 computers for different purposes as a developer, take the time to setup a good dotfiles repo that contains the configs for the command line programs and editors you use.  These days if you do that, pretty much everything else but the operating system will come right along.</p>
<p>[^1]: Honestly the wording around that feature is pretty insulting.</p>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
        <item>
            <title><![CDATA[The Mystery of Docker and the Disk-Eating Cow]]></title>
            <link>https://benmccormick.org/2017/03/28/the-mystery-of-docker-and-the-disk-eating-cow/</link>
            <guid>https://benmccormick.org/2017/03/28/the-mystery-of-docker-and-the-disk-eating-cow/</guid>
            <pubDate>Tue, 28 Mar 2017 14:40:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Yesterday morning I was innocently minding my own business, downloading some files, when I noticed that nearly all the disk space on my 256GB work laptop had been consumed.  This seemed rather unlikely to me, given that I’d only had the laptop for about a year and I didn’t store anything other than code and work documents on it.  Text files just don’t take up that much space most of the time.  So I decided to make a purchase I’d considered for a while, bought <a href="https://daisydiskapp.com/">Daisy Disk</a>, and began investigating.</p>
<p>The first thing I noticed was a huge amount of the disk space (about half) was taken up by the <code>~/Library/Containers</code> folder. That folder contained my email history and also data on my <a href="https://www.docker.com/">Docker</a> containers. Docker functions as a lightweight VM, and essentially holds copies of virtualized operating systems and file systems inside each docker container and image, so it made sense to me that it could be taking up a lot of space, though &gt;120GB still seemed wrong for my paltry 4 containers.  So my first step was to delete all of the containers and images on my laptop.  That cleared about 20GB of space but still left my drive looking like this:</p>
<p><img alt="daisy disk showing 100+GB of docker" src="http://benmccormick.org/posts/images/docker-cow/daisy.png"
class="full-width"></p>
<p>At this point, I was annoyed.  103.5 GB was taken up by some folder called Docker.qcow2 and Daisy Disk wouldn’t show me what was inside.  So I drilled in on the file system and immediately found out that Docker.qcow2 was not a directory like I’d assumed due to size, but a single 100+GB file.  At that point I decided to poll my teammates to see if I was the only one dealing with this:</p>
<p><img alt="daisy disk showing 100+GB of docker" src="http://benmccormick.org/posts/images/docker-cow/slack.png"
class="full-width"></p>
<p>So between the 5 of us, we each had “cow files” taking up between 23 and 103GB of disk space. Some Googling revealed a <a href="https://github.com/docker/for-mac/issues/371">github thread</a> that showed this is a so far unsolved issue with Docker For Mac.  Summary: qcow2 files are a format for saving disk images.  Docker For Mac’s implementation works well for writing and updating images, but doesn’t automatically free up disk space when a container or image is deleted. So as you use and delete containers over time this file gradually grows.  I have a habit of deleting and recreating containers when I’m trying to debug something, which explains why I had a much larger file than others.  There isn’t currently a true fix for this issue, but you can delete the file.  You’ll lose all your containers and images, but when you recreate them the file will be small again.  There also is supposed to be some automatic limiting of the file.  The current cap is 64GB, but there is work on making it configurable.  Unfortunately the current cap is not respected if you had previously used docker-machine to control docker on your machine, which is how my file exceeded the cap.  I’m also unclear on what happens when the file hits the cap.  I get the impression that things stop working and you need to delete everything anyway (you just avoid running out of disk space on the host machine).</p>
<p>Fortunately it was no problem for me to delete everything, and so I was able to clear things out, at which point my disk looked a lot happier:</p>
<p><img alt="daisy disk showing 100+GB of docker" src="http://benmccormick.org/posts/images/docker-cow/daisy2.png"
class="full-width"></p>
<h3>Lessons Learned</h3>
<p>I had 3 takeaways from this interesting adventure.</p>
<ol>
<li>If you’re using Docker For Mac, keep an eye on your disk space.  If you’re able to occasionally delete and recreate your containers without data loss, consider occasionally doing that and deleting the cow file.  If you can’t do that, be careful how many containers you add and delete, and make sure you manage your disk space well.</li>
<li><a href="https://daisydiskapp.com/">Daisy Disk</a> is awesome and highly recommended.  It’s an example of a rare breed: the beautiful system utility. The visualizations it shows are both pretty and useful; it made diagnosing this issue a breeze.</li>
<li>One more thing I learned from my coworkers slack yesterday: <code>ls</code> takes an <code>-h</code> argument that shows file sizes in KBs/MBs/GBs instead of all in bytes.  This is super helpful when examining large files.  Compare the 2 lists of files from my Downloads folder in the image below. The normal form is very nice for comparing 2 files side by side and seeing which one is bigger, but the second form is much more helpful when you want to get an idea of exactly how big something is, or communicate it to others.  Most of us don’t think about file sizes in terms of bytes anymore.</li>
</ol>
<p><img alt="daisy disk showing 100+GB of docker" src="http://benmccormick.org/posts/images/docker-cow/downloads.png"
class="full-width"></p>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
        <item>
            <title><![CDATA[Running Jest Tests Before Each Git Commit]]></title>
            <link>https://benmccormick.org/2017/02/26/running-jest-tests-before-each-git-commit/</link>
            <guid>https://benmccormick.org/2017/02/26/running-jest-tests-before-each-git-commit/</guid>
            <pubDate>Sun, 26 Feb 2017 23:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>My main work project makes heavy use of <a href="https://facebook.github.io/jest/">Jest</a> to test our JavaScript code.  For a while now I’ve wanted to set up a way to run tests every time I run a commit.  I knew that git provides <a href="https://git-scm.com/book/en/v2/Customizing-Git-Git-Hooks">hooks</a> that allow scripting actions to occur before or after any commit or push, and in fact we were already using a <code>pre-commit</code> hook script to lint our code with <a href="http://eslint.org/">ESLint</a>.  But it was non-obvious how to make that work well with Jest testing.  I eventually figured out a setup that worked, and the found a better way to do both the Jest and ESLint testing.  Since it took me a while to work through, I thought I’d share it here and save the rest of you some time.</p>
<h3>What didn’t work</h3>
<p>A naive approach to this problem would be to set up a pre-commit hook that simply ran <code>jest</code> to run all tests. The problem is that running our full test suite currently takes between 10 and 20 seconds to run all tests and that time is increasing as we grow our test suite.  Adding that overhead to every commit would cost my team a lot of time, and would be especially inefficient since the repo contains plenty non-JavaScript code that doesn’t require tests to be run when updated.</p>
<p>For our ESLint hook, we queried git to get a list of staged files, and then ran eslint against each one of them individually, displaying a pass/fail message.  That looked something like this:</p>
<pre><code class="language-bash">STAGED_FILES=$(git diff --cached --name-only --diff-filter=ACM | grep &quot;js$&quot;)
if [[ &quot;$STAGED_FILES&quot; = &quot;&quot; ]]; then
    exit 0
fi

PASS=true

for FILE in $STAGED_FILES
do
    eslint --quiet &quot;$FILE&quot;

    if [[ &quot;$?&quot; == 0 ]]; then
        echo &quot;\t\033[32mESLint Passed: $FILE\033[0m&quot;
    else
        echo &quot;\t\033[41mESLint Failed: $FILE\033[0m&quot;
        PASS=false
    fi
done
</code></pre>
<p>This works great for ESLint, but doesn’t work out of the box for Jest, because I don’t want Jest to run the files that changed, I want them to run any tests that changed AND any tests that might have been broken because of that.</p>
<p>Jest has a wonderful command line flag <code>jest --onlyChanged</code>/<code>jest -o</code> that runs only the tests related to files that have been changed according to git.  It is extremely helpful since it is smart enough to read the dependency structure for the project and run all tests that might be changed from updating a source file. It also has a <code>--lastCommit</code> option that does the same thing for files that were in the previous commit.  Unfortunately, these options aren’t helpful at the point of committing, since <code>onlyChanged</code> does not look at files that have been staged for commit, and we haven’t actually made a commit yet for <code>lastCommit</code> to read.</p>
<h3>What Did Work</h3>
<p>Fortunately Jest has a lower level command that uses the same logic as <code>onlyChanged</code> and <code>lastCommit</code>.  <code>--findRelatedTests</code> is a flag that tells Jest to run any tests related to the files passed to it instead of trying to run those files as tests as it would normally do.</p>
<img alt="an example of findRelatedTests running against the redux repo" src="http://benmccormick.org/posts/images/jest-related-tests.png" class="full-width ">
<p>This is a perfect fit for a pre-commit hook.  I was able to integrate it into my existing script like this:</p>
<pre><code class="language-bash">jest --bail --findRelatedTests $STAGED_FILES
if [[ &quot;$?&quot; == 0 ]]; then
    echo &quot;\t\033[32mJest Tests Passed\033[0m&quot;
else
    echo &quot;\t\033[41mJest Tests Failed\033[0m&quot;
    PASS=false
fi
</code></pre>
<p><code>$STAGED_FILES</code> is re-used from the eslint portion of the script, and is just a space delimited list of files that are being committed.  The <code>--bail</code> option simply stops running tests as soon as one has failed.  Including that is optional, you won’t see all the tests that have failed, but the failure will happen faster and you’ll be able to decide how to proceed, including possibly running the full test script on your own.</p>
<p>Those lines (along with some sanity checks for the existence of Jest and error handling when PASS is set to false) are enough to get a workable commit hook going, but they’re not ideal.  pre-commit hooks aren’t persisted by git, so each user has to install the hook script individually, and any updates aren’t shared automatically.  Plus I’m inefficiently passing all staged files to eslint and Jest regardless of whether they’re JavaScript that those tools are actually meant to work on.  My ESLint code was also written before ESLint developed robust <code>--fix</code> capabilities, and doesn’t try to fix the errors it is capable of fixing.  Finally, while this is just poor coding and not an inherent limitation of my other method, I’m using globally installed versions of Jest and ESLint instead of scoping them to my project.</p>
<h3>Making it better</h3>
<p>Fortunately I’d discovered a better solution the other day while working on something else.  There is an npm package for making this process easier, <a href="https://github.com/okonet/lint-staged">lint-staged</a>.  Lint staged abstracts away the boilerplate of getting the staged files, and makes it easy to run local node executables against specific sets of files.  I was able to replace my whole pre-commit script and address all of the problems mentioned above with only a few lines in my package.json:</p>
<pre><code class="language-json">{
  &quot;scripts&quot;: {
    &quot;lint-staged&quot;: &quot;lint-staged&quot;,
  },
  &quot;lint-staged&quot;: {
    &quot;*.js&quot;: [
      &quot;eslint --fix&quot;,
      &quot;git add&quot;,
      &quot;jest --bail --findRelatedTests&quot;
    ]
  },
  &quot;devDependencies&quot;: {
    &quot;eslint&quot;: &quot;3.16.1&quot;,
    &quot;jest&quot;: &quot;19.0.1&quot;,
    &quot;lint-staged&quot;: &quot;3.3.1&quot;,
  },
}
</code></pre>
<p><code>lint-staged</code> now handles making sure that I’m only running checks against JavaScript files, lets eslint autofix and stage any files that it can fix, and uses the local versions of jest and eslint.  It also adds a nice pretty interface for the results:</p>
<img alt="pretty lint-staged output" src="http://benmccormick.org/posts/images/lint-staged-errors.png" class="full-width ">
<p><code>lint-staged</code> docs recommend using an npm based hooks manager like <a href="https://github.com/observing/pre-commit">pre-commit</a> for running the scripts, but due to some quirks in my setup (node_modules is symlinked, and I sometimes want to run these commands inside a docker container), I found it easier to maintain a custom pre-commit script and just replace the previous logic with <code>npm run lint-staged</code>.  Either way, all of the actual logic is now checked into the repository and shared between all users.  The only manual step is adding the call to a pre-commit hook or (if you’re using a helper lib) running npm install.</p>
<h3>More Resources</h3>
<ul>
<li>This maybe merits a future post on its own, but if you’re interested in automating away your code style maintenance look at combining <a href="https://github.com/prettier/prettier">prettier</a> (and possibly  <a href="https://github.com/not-an-aardvark/eslint-plugin-prettier">eslint-plugin-prettier</a>) with the pre-commit hooks from above.  Prettier will guarantee that your code follows a consistent style, and because it handles maximum line lengths, is much more robust than ESLint on its own.  Using its ESLint plugin within my editor and on pre-commit hooks has pretty much eliminated me manually fixing code style problems.</li>
</ul>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
        <item>
            <title><![CDATA[Giving Context to Best Practices]]></title>
            <link>https://benmccormick.org/2017/02/18/context-to-best-practices/</link>
            <guid>https://benmccormick.org/2017/02/18/context-to-best-practices/</guid>
            <pubDate>Sat, 18 Feb 2017 23:30:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I’ve noticed a frustrating trend in online discussions about web development where developers take their personal experience with a tool or practice and promote it as a universal truth.  Some of this is the nature of being human: we all see the world through our own lens.  But the best technical observations exist within a specific context.</p>
<p>Compare</p>
<blockquote>
<p>Everybody should be writing code using static types, the extra syntax is worth it because of all the bugs it prevents.</p>
</blockquote>
<p>to</p>
<blockquote>
<p>If you’re working in a large code base with many developers, static typing is extremely useful, because the overhead from writing extra code and compiler errors is more than made up for by reducing bugs and clearly expressing intent when developers edit code they didn’t write.</p>
</blockquote>
<p>The first quote presents a tradeoff and declares a universal preference for one direction in the tradeoff.  The second quote adds more details about the context in which the practice has been beneficial, and explains what about those circumstances (developers editing code they didn’t write) affects the tradeoff decision.</p>
<p>These type of distinctions are often lost in online discussions about development best practices. I have no interest in naming and shaming, but specifically I’ve seen this in discussions around JavaScript performance, testing, frameworks vs other frameworks vs VanillaJS, responsive design, progressive enhancement, and build pipelines.  For this post, I’m going to try to lay out a list  of some of the context that I’ve found helpful to take into account when giving or interpreting best practice advice.</p>
<h3>Context to keep in mind when discussing and interpreting best practices</h3>
<h4>Beginner vs Veteran</h4>
<p>I’ll start with a distinction that folks seem better about making. Sometimes recommendations that make sense for beginners don’t work as well for more experienced developers and vice versa.  For instance it might make sense to advise a more experienced developer to use and heavily configure a build system like <a href="https://webpack.github.io/">Webpack</a> for a new project. But beginners already have a lot to learn with each new project and might benefit from a simpler system; either a simple project without a build step, or a “batteries included” system like <a href="https://github.com/facebookincubator/create-react-app">Create React App</a> or <a href="https://ember-cli.com/">Ember CLI</a>.  Making these distinctions is important for helping developers who may feel overwhelmed by all the concepts they need to learn when getting started with web development.</p>
<h4>Big Team vs Small team vs Individual</h4>
<p>Another dynamic that matters when expressing best practices is the size of a team working on a project.  If a project is being developed by a large team, or several teams, or is meant to be used as a library by many people, techniques like automated documentation, static type checking, and clear style guidelines may be essential.  But for a personal project or a professional project run by a 1 person team, those same techniques may provide a lot of overhead for minimal benefit. Most teams will fall between those extremes and will have to weigh the tradeoffs in each case.</p>
<h4>Personal Project vs Internal tool vs B2B Products vs Consumer Products</h4>
<p>The audience of a project is also important.  Some projects we build for ourselves.  Some may be internal for a company, or for a group that we’re a part of.  Other projects are sold professionally to businesses or offered freely to consumers on the web.  There are different goals and expectations for each of these groups, that may impact which practices and techniques are important.  For instance, nobody cares if a personal web application you’ve made to organize your todos crashes in Internet Explorer or doesn’t have alt-text for images.  But browser compatibility and accessibility might be extremely important for a consumer web app aimed at a broad population.  Similarly, it might be ok for your internal web tool to have un-minified JavaScript and large un-optimized CSS and JavaScript bundles, since it will always be served locally over a fast connection.  But it could severely hurt the user experience to do the same things for a high traffic public site.</p>
<h4>Web page vs Web app</h4>
<p>Distinguishing between web pages[^1] and web apps[^2] would short circuit a large number of internet arguments before they started.  Specifically arguments about progressive enhancement, whether we use too much JavaScript and whether a site is “acceptable” if it doesn’t work without JavaScript.  Many accessibility and performance proponents push very strongly for less JavaScript and sites that work without JavaScript.  And that is a good thing… for the sites that <strong>can</strong> function without JavaScript.  Web apps like Trello, Google Docs, or Postman just don’t make sense without JavaScript.  But saying that we should use less JavaScript isn’t bad advice, it’s just bad advice when given or taken without context.</p>
<h4>Existing project vs Greenfield project</h4>
<p>Some choices are only easy to make at the start of a project.  It is possible to change the language or framework a project is written in midstream, but it is often extremely risky and painful.  So asking a developer working on a 5 year old JavaScript project with thousands of lines of code why they didn’t write it in <a href="http://elm-lang.org/">Elm</a> or <a href="https://clojurescript.org/">ClojureScript</a> is not helpful.  But suggesting that somebody write a new project in Elm may be just fine.</p>
<h4>Short term project vs Long term project</h4>
<p>Some software projects are meant to be written, completed, and never seen again.  For instance a promotional site for an event.  Some projects, like financial software, are meant to last for decades.  This is yet another distinction than can impact best practice discussions.  When working on a short term project, speed of delivery and initial quality tend to matter a lot.  For long term projects it may be better to prioritize maintainability, security and ease of deployment.</p>
<p>[^1]: Web page: sites that are mostly content focused with some possible interactivity layered on top
[^2]: Web app: sites that are primarily an interactive experience for the user and behave more like traditional desktop or mobile applications</p>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
        <item>
            <title><![CDATA[Evaluating Web Apps With Lighthouse]]></title>
            <link>https://benmccormick.org/2017/02/13/improving-site-performance-with-lighthouse/</link>
            <guid>https://benmccormick.org/2017/02/13/improving-site-performance-with-lighthouse/</guid>
            <pubDate>Tue, 14 Feb 2017 03:30:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Last year Google coined the term “Progressive Web App” as a way of describing the type of sites and applications that they think are the future of the web.  Progressive Web Apps are sites that load quickly, are always responsive to user input, work as well as possible offline, and integrate with native platforms like native apps.  While this site is not an “app” per say, I do want it to be as fast and responsive as possible, and I also wanted to better understand what Google is pulling under the PWA umbrella.  Fortunately, Google has built a tool <a href="https://developers.google.com/web/tools/lighthouse/">Lighthouse</a> to help developers profile and improve their web applications, comparing them to a set of PWA benchmarks.  So I took this site through Lighthouse, and worked against their suggestions with the goal of learning more about PWAs and improving the experience of using <a href="http://benmccormick.org">benmccormick.org</a>.  I’m passing along my experience here.</p>
<h3>Getting Started</h3>
<p>I began by downloading the Lighthouse extension in the <a href="https://chrome.google.com/webstore/detail/lighthouse/blipmdconlkpinefehnmjammfjpmpbjk">Chrome Web Store</a>.  Lighthouse can be installed either as a chrome extension or a node command line tool.  Both produce the same HTML report, but I chose the chrome extension for the convenience of keeping everything in the browser.  When I ran the initial report, I got the following result:</p>
<img alt="first score: 48/100" src="http://benmccormick.org/posts/images/lighthouse/first_report_summary.png" class="full-width bordered-img">
<p>48 out of 100 didn’t seem like a bad starting place.  Scrolling down it looked like I was mainly dinged on a few main areas:</p>
<ol>
<li>I had no offline support</li>
<li>I did’t have any special setup for being included on a users homescreen. (I did have platform appropriate icons, but no app configuration)</li>
<li>I had some possible inefficiencies in the assets I loaded.</li>
</ol>
<img alt="offline issues" src="http://benmccormick.org/posts/images/lighthouse/first_report_offline.png" class="full-width bordered-img">
<img alt="native issues" src="http://benmccormick.org/posts/images/lighthouse/first_report_native.png" class="full-width bordered-img">
<img alt="asset issues" src="http://benmccormick.org/posts/images/lighthouse/first_report_assets.png" class="full-width bordered-img">
<p>Native app support isn’t a huge priority for me, and the assets issue seemed small, so I decided to investigate the offline support issue first.</p>
<h3>Offline</h3>
<p>I based my service worker implementation off of <a href="https://github.com/chriscoyier/Simple-Offline-Site">Simple Offline Site</a> a demo Service Worker repo created by Chris Coyier for an article on <a href="https://css-tricks.com/serviceworker-for-offline/">CSS Tricks</a>.  This was perfect since it’s default behavior was what I wanted: cache everything, and check for updates from the server everytime we return from cache so we’re never out of date for long.  You can see what I did specifically in my <a href="https://github.com/benmccormick/benmccormickorg/blob/master/pages/sw.es6">github repo for this site</a>. After adding the service worker, my score moved up to 63/100.</p>
<p>Finally, Service Workers only work on HTTPS connections, but most links to my site are not https currently. So to take full advantage (and to address another metric I was flagged on), I used a <a href="https://support.cloudflare.com/hc/en-us/articles/200170536-How-do-I-redirect-all-visitors-to-HTTPS-SSL-">CloudFlare page rule</a> to redirect all visting traffic to use https.  That bumped me up to 69/100.</p>
<img alt="asset issues" src="http://benmccormick.org/posts/images/lighthouse/second_report_offline.png" class="full-width bordered-img">
<h3>Native Support</h3>
<p>As I said previously, native platform support isn’t a major priority for this blog, but I was curious about the process.  Getting native support turned out to be very straightforward.  I had already collected icons for the various platforms, and created a simple manifest when I originally created a favicon for my site.  But the manifest file didn’t have everything and it wasn’t being deployed properly to my site.  Fixing that and making it available at <code>/manifest.json</code>, fixed all of the problems related to native platform support.</p>
<p>My manifest file now looks like this:</p>
<pre><code class="language-json">{
	&quot;name&quot;: &quot;benmccormick.org&quot;,
  &quot;short_name&quot;: &quot;benmccormick&quot;,
	&quot;icons&quot;: [
		{
			&quot;src&quot;: &quot;\/android-chrome-192x192.png?v=yyxgnp97qG&quot;,
			&quot;sizes&quot;: &quot;192x192&quot;,
			&quot;type&quot;: &quot;image\/png&quot;
		},
		{
			&quot;src&quot;: &quot;\/android-chrome-384x384.png?v=yyxgnp97qG&quot;,
			&quot;sizes&quot;: &quot;384x384&quot;,
			&quot;type&quot;: &quot;image\/png&quot;
		}
	],
	&quot;theme_color&quot;: &quot;#ffffff&quot;,
	&quot;background_color&quot;: &quot;#57a3e8&quot;,
	&quot;display&quot;: &quot;browser&quot;
}
</code></pre>
<p>After correctly deploying that manifest file, my score moved all the way up to 100/100!</p>
<img alt="asset issues" src="http://benmccormick.org/posts/images/lighthouse/third_report_native.png" class="full-width bordered-img">
<p>I clearly benefited from starting in a good spot.  <a href="https://github.com/gatsbyjs/gatsby">Gatsby</a> is “fast by default” as a platform for building blogs, and I’ve done my best to avoid making it slow.  But it was fun seeing what I could do to make the site a better experience for users with bad connectivity, and to learn more about what Google is trying to do with PWAs.</p>
<h3>More Resources</h3>
<ul>
<li>
<p>Google has a bunch of resources around creating Progressive Web Apps.  You can find them on <a href="https://developers.google.com/web/progressive-web-apps/">their PWA landing page</a>.</p>
</li>
<li>
<p>It was so easy to make my blog a PWA mostly because it is built on <a href="https://github.com/gatsbyjs/gatsby">Gatsby</a>. Worth looking at if you’re a web developer who blogs.</p>
</li>
</ul>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
        <item>
            <title><![CDATA[MobX: First Impressions]]></title>
            <link>https://benmccormick.org/2017/01/09/mobx-first-impressions/</link>
            <guid>https://benmccormick.org/2017/01/09/mobx-first-impressions/</guid>
            <pubDate>Mon, 09 Jan 2017 13:30:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>I spent some time around the holidays this year playing with <a href="https://mobx.js.org/">MobX</a>, a state management library for JavaScript.  MobX is an unopinionated library that provides a layer over normal JavaScript data structures that allow other code to efficiently observe data changes and update based on what has changed.  It’s an interesting tool for handling state in web applications, especially in existing projects that might need to update state handling iteratively.  Here are some first impressions.</p>
<h3>What is MobX?</h3>
<p>MobX has 3 core concepts developers need to understand:</p>
<ol>
<li><strong>Observable state</strong> - MobX provides functions to make data <em>observable</em>.  Observable data can be watched by other pieces of code which may efficiently update when the state changes.  Observable data is primarily created in MobX using the <code>observable</code> function.</li>
<li><strong>Derivations</strong> - Functions that <em>watch</em> observable data are called derivations.  MobX has 2 primary types of derivations: <em>computed values</em> and <em>reactions</em>.  Computed values update a value based on other data, while reactions produce side effects: updates to a UI, a network call, or a logging statement for example. MobX provides a <code>computed</code> function for defining computed values; in most cases reactions will likely be mostly defined using a framework specific helper library like <a href="https://github.com/mobxjs/mobx-react">mobx-react</a> or <a href="https://github.com/500tech/ng2-mobx">ng2-mobx</a>.  MobX does provide some lower level libraries for reactions though, including <code>autorun</code> and <code>when</code>.</li>
<li><strong>Actions</strong> - Code that updates observable state is known as an action.  MobX has a formalized version of actions which can be defined using the <code>action</code> function, but it is also possible to modify state directly using any normal JavaScript code and maintain observable behavior.</li>
</ol>
<p>In practice this looks something like this:</p>
<pre><code class="language-javascript">import React from 'react';
import ReactDOM from 'react-dom';
import {observable} from 'mobx';
import {observer} from 'mobx-react';

let digits = observable([1, 2]);

const DigitPrinter = observer(({digits}) =&gt; {
  return (&lt;div&gt;
    {digits.join(', ')}
  &lt;/div&gt;);
});

ReactDOM.render( &lt;DigitPrinter digits = {digits} /&gt;, document.getElementById('root'));

/* prints 1, 2 */


digits.push(3);

/* DOM re-renders to print 1, 2, 3 */

digits[2] = 4;

/* DOM re-renders to print 1, 2, 4 */

</code></pre>
<p>The component is able to passively <em>observe</em> changes in the data, and re-render when it changes.  But MobX is actually even smarter than this example shows.  Let’s look at another example, this time using a more complex data structure (a class).</p>
<pre><code class="language-javascript">import React from 'react';
import ReactDOM from 'react-dom';
import {extendObservable} from 'mobx';
import {observer} from 'mobx-react';
import moment from 'moment';

class Appointment {

  constructor() {
    extendObservable(this, {
      dueDate: '01-01-2017',
      title: 'Dinner with Joe'
      location: 'Chik-Fil-A',
      isToday: computed(function() {
        return moment(dueDate, 'MM-DD-YYYY').diff(moment.now(), 'days') === 0;
      }),
    });
  }

  toString() {
    return `${this.title} @ ${this.location}`;
  }
}


const TodayBox = observer(class TodayBox extends React.Component {
  render () {
    let {appointments} = this.props;
    return (&lt;div&gt;
      {appointments.filter(a =&gt; a.isToday).map(a =&gt; &lt;span&gt;a.toString()&lt;/span&gt;)}     
    &lt;/div&gt;);
  }
});

let appointment = new Appointment();

ReactDOM.render( &lt;TodayBox appointments = {[appointment]} /&gt;, document.getElementById('root'));

/* prints an empty div */

appointment.title = 'Dinner with Bob';

/* Nothing relevant has changed. The component does not re-render */

appointment.dueDate = '01-09-2017';  

/*  assume that 01-09-2017 is &quot;today&quot; */
</code></pre>
<p>MobX has the “magical” ability to determine what changes actually affect the observer and not make unnecessary calls of reaction functions.  In practice, that magic allows you to write less, more efficient code for updating your UI based on data.</p>
<h3>How Does MobX work?</h3>
<p>I have a learned skepticism of magical solutions like this.  Generally I find that time-saving magic like this ends up costing time when it comes to maintenance, and explicit relationships between code saves time over less-boilerplate heavy code. Fortunately, while the libraries code itself is fairly complex, it isn’t too hard to understand the logic behind how MobX works.</p>
<p>On the Observer side, MobX uses <a href="http://benmccormick.org/2015/09/14/es5-es6-es2016-es-next-whats-going-on-with-javascript-versioning/">ES5</a> setters and getters to proxy updates to observable data structure and listen in when data is updated.  This allows the type of event listening that <a href="http://backbonejs.org/">Backbone</a> and other libraries provide, without requiring the user to go through special <code>set</code> or <code>get</code> methods to update an object’s properties.  Most of the time you should be able to just be able to write code as you normally would, and MobX will make it work.  There are some exceptions though that mean its important to actually understand how the library work.  Getters and Setters only work when looking up an existing property on an object, so when using primitive values or adding new values to an existing object, some special syntax (the return of <code>get</code> and <code>set</code> methods) may be required.  In Mobx primitive observables are referred to as <em>boxed</em> values, and objects that require new values over time can be handled by using observable Maps, which use the API of <a href="http://benmccormick.org/2015/09/14/es5-es6-es2016-es-next-whats-going-on-with-javascript-versioning/">ES6</a> Maps.</p>
<p>On the derivative side, reactions and computed values are always defined as functions.  MobX wraps these functions and is able to determine (through the method described above) what properties were accessed during each function run.  It then only listens for changes to these properties.  Thus it doesn’t matter if you theoretically could access thousands of observable properties in a function, if you wrap those references in an if statement to a single property, and that property returns false on first run, the derivative function will only listen for changes on that property before running again. When an observable is updated, all derivative code is run synchronously and atomically so there is no concern of getting into bad intermediate states.</p>
<p>Most of the “magic” is covered by the 2 paragraphs above, and once you understand the ideas behind them (see the resources at the bottom of this post for more in-depth explanations), it is fairly easy to understand the reasoning behind the cases where the magic fails.</p>
<h3>Decorators</h3>
<p>Developers who actually use MobX are probably questioning my examples by now, because I’ve been using a different syntax than the primary MobX documentation for showing my examples.  So let’s talk about decorators.  The preferred way (according to the documentation) to write MobX code is to use decorators to define observers and observables.  Decorators are a <a href="http://tc39.github.io/proposal-decorators/">proposed new JavaScript feature</a> for declaratively adding extra behavior to classes, class properties and class methods.  Using them with MobX, my above example would look like this [^1]:</p>
<pre><code class="language-javascript">
class Appointment {

  @observable dueDate = '01-01-2017'
  @observable title = 'Dinner with Joe'
  @observable location = 'Chik-Fil-A'

  @computed get isToday() {
    return moment(dueDate, 'MM-DD-YYYY').diff(moment.now(), 'days') === 0;
  }

  toString() {
    return `${this.title} @ ${this.location}`;
  }
}


@observer class TodayBox extends React.Component {
  render () {
    let {appointments} = this.props;
    return (&lt;div&gt;
      {appointments.filter(a =&gt; a.isToday).map(a =&gt; &lt;span&gt;a.toString()&lt;/span&gt;)}     
    &lt;/div&gt;);
  }
}
</code></pre>
<p>That obviously looks a lot cleaner than my example.  So what’s the problem?  Again, decorators are a <em>proposed</em> JavaScript feature.  Currently they’re in Stage 2, which means roughly that they are very likely to eventually make it into the language, but may change in non-trivial ways before that happens.  Currently decorators are implemented in <a href="https://www.typescriptlang.org/docs/handbook/decorators.html">TypeScript</a>, as well as a <a href="https://github.com/loganfsmyth/babel-plugin-transform-decorators-legacy">3rd party babel plugin</a>, but as of January 2017 <a href="http://kangax.github.io/compat-table/esnext/#test-class_decorators">are not implemented in any browser engines</a>, and are not implemented in any first party babel plugins <a href="https://github.com/babel/babel/issues/2645">due to spec instability</a>.  Decorators are a key part of Angular2, and are used by other frameworks including <a href="http://aurelia.io/">Aurelia</a> and <a href="https://github.com/rwjblue/ember-computed-decorators">Ember</a>, so I don’t think they’re going away.  But I also don’t see them as ready for production use for teams that don’t have the capacity to dedicate the time to update existing code if/when the spec changes[^2].  If for one reason or other you’re comfortable with the risks however, decorators are a great way to clean up the MobX API, and I’m excited for the spec to get to the point where I can use them.</p>
<h3>Comparison to Redux and setState</h3>
<p>As a state management library that was built to be used with React, the obvious questions to ask about MobX are how it improves over React’s built in state handling, and how it compares to <a href="http://redux.js.org/">Redux</a>, the current most popular state management solution for React. MobX takes a different approach to each.</p>
<p>It’s important to say at the start that MobX isn’t mutually exclusive with using setState.  It’s possible to use them together, with MobX managing application data and setState handling individual component/UI state.  But there is some advantages to using MobX for UI state as well.  The biggest reason is that MobX is smarter than setState about when re-rendering is required.  By default React Components re-render on any call to setState, regardless of whether the state change actually affects what is rendered or not. MobX’s creator <a href="https://medium.com/@mweststrate/3-reasons-why-i-stopped-using-react-setstate-ab73fc67a42e#.x0o6y4rxv">wrote more about this on Medium</a>.</p>
<p>Comparing MobX and Redux could be a whole article on its own, so I’m not going to go too deep here, but suffice it to say that MobX is more flexible than Redux, but as a result loses some of the benefits of Redux’s structured approach.  Specifically, it is easy to convert a single object to become a MobX observable and use it in an existing React component.  It can be easily inlined in an existing file and used for one component even.  You also don’t have to deal with the ceremony of using <a href="http://benmccormick.org/2016/06/04/what-are-mutable-and-immutable-data-structures-2/">immutable data</a>.  Redux is intended as a solution that will take over all your state, and doesn’t scale down nearly as well or mix with other solutions [^3].  However, Redux’s structure also has benefits.  It allows easy testings of each component of an app individually, the creation of powerful tooling that will work with any Redux app, and reliable guarantees of how state will be updated.  These things are mostly possible with MobX [^4], but require more developer discipline, and/or can’t be written as easily as universal tools. Overgeneralizing, I would prefer Redux in a new application, but would look to MobX for improving data management in an existing application.  MobX also has advantages in applications where you’re displaying a large amount of UI elements based on a relatively small amount of data, or have a lot of derived data (something like a spreadsheet), whereas Redux has benefits for applications that need to be extremely reliable and well tested.</p>
<h3>Stray Thoughts</h3>
<ul>
<li>If you do want more discipline in MobX, make sure to use <code>useStrict</code> to require updates to use Actions</li>
<li>MobX has a nice set of <a href="https://github.com/mobxjs/mobx-react-devtools">devtools</a> that are useful if you’re opting in to using actions, and using React with MobX.</li>
<li>If this isn’t clear yet, I definitely recommend hacking around with Mobx’s low level APIs to learn more about how it works before integrating it straight into a framework</li>
<li><s>Also note that MobX 3.0 is imminent, there is a release candidate that you can play with now.</s> <strong>Update:</strong> That didn’t take long.  <a href="https://medium.com/@mweststrate/mobx-3-released-unpeeling-the-onion-ca877382f443#.mk6mdypt2">MobX 3.0 is out</a>.</li>
</ul>
<h3>More Resources</h3>
<ul>
<li>
<p>The two most helpful resources I found for conceptually understanding MobX were in-depth articles by the library’s author <a href="">Michael Westrate</a>: <a href="https://medium.com/@mweststrate/becoming-fully-reactive-an-in-depth-explanation-of-mobservable-55995262a254#.jd4hgh2zi">Becoming fully reactive: an in-depth explanation of MobX</a> on Medium and <a href="https://mobx.js.org/intro/concepts.html">Concepts &amp; Principles</a> from the MobX documentation</p>
</li>
<li>
<p>This <a href="https://twitter.com/AdamRackis/status/775706291259908096">tweet thread</a> and the linked article, are a good breakdown of the tradeoffs between MobX and Redux</p>
</li>
</ul>
<p>[^1]: Technically this also uses class properties as well, another proposal that works well with decorators
[^2]: It’s possible any spec changes will be trivially fixable with a code mod script, but right now there is more uncertainty than I am personally comfortable with.  I’m grateful to people who are willing to take more risks here than me, they push the language forward.
[^3]: I’m talking here about what is encouraged and easy, not what is possible.  It is of course possible to mix in Redux with other solutions.
[^4]: MobX has some nice <a href="https://github.com/mobxjs/mobx-react-devtools">devtools!</a></p>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
        <item>
            <title><![CDATA[Orthogonality and CSS in JS]]></title>
            <link>https://benmccormick.org/2017/01/03/orthogonality-and-css-in-js/</link>
            <guid>https://benmccormick.org/2017/01/03/orthogonality-and-css-in-js/</guid>
            <pubDate>Tue, 03 Jan 2017 00:00:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>One of the realities of the constant change in the web development world is that “best practices” are often hotly contested.  One issue that the front end community doesn’t seem to have come to a consensus on yet is how tightly to bundle JavaScript, HTML and CSS in code.  Should they be bundled and managed completely separately?  Kept in different files and imported together into JavaScript component files?  Or can we remove HTML and CSS files entirely and generate everything in JavaScript? This is a discussion that still comes up all the time in my <a href="https://twitter.com/thomasfuchs/status/810885087214637057">twitter</a> <a href="https://twitter.com/TheLarkInn/status/812089065210335232">feed</a>.</p>
<p>Many new frameworks that encourage a component based architecture (including React, Vue, and Angular2 [^1]) provide affordances for including HTML and CSS directly in JavaScript, but those solutions are not yet used universally.  Many people are still very happy keeping CSS bundled separately.  I have no idea what the <em>best</em> solution is.  But I am interested in how people talk about the problem.  One major argument I have seen from people advocating both sides is that their preferred approach encourages good “separation of concerns”.</p>
<div>
<blockquote class="twitter-tweet" data-lang="en"><p lang="en" dir="ltr">I&#39;m moving from storing my CSS, JS and HTML in different files, to physically putting them on different drives. Keep those concerns separate</p>&mdash; Ben Lesh (@BenLesh) <a href="https://twitter.com/BenLesh/status/812092408519413761">December 23, 2016</a></blockquote>
</div>
<p>I’d like to take a deeper look at this and give some vocabulary that can hopefully help anyone working through discussions on how to manage CSS for components.  I’ll focus specifically on CSS since frameworks tend to be more agnostic to how it is blended with JS than they are about HTML, and on components since that is the main context in which people are arguing for blending of css. For this piece, I’ll consider a component to be a set of HTML, CSS, and JavaScript that combine to form a reusable piece of UI [^2].</p>
<h3>Orthogonality, Cohesion, and Coupling</h3>
<p><a href="http://amzn.to/2hNzQ0t">The Pragmatic Programmer</a>, one of the best books ever written on Software Engineering, uses the following three terms when talking about “Separation of Concerns”: orthogonality, cohesion, and coupling.</p>
<p>Orthogonality is the idea that modules should be written in a way that a change in one module should not require changes in any other module.</p>
<blockquote>
<p>Two or more things are orthogonal if changes in one do not affect any of the others. In a well-designed system, the database code will be orthogonal to the user interface: you can change the interface without affecting the database, and swap databases without changing the interface.</p>
<p><strong>— The Pragmatic Programmer</strong></p>
</blockquote>
<p>Cohesion is a measure of how well the internal contents of a module relate to each other. A cohesive module is one with a single well defined purpose, where all code in the module is related to that purpose.  A less cohesive module might have multiple purposes, with pieces of code that are completely unrelated to each other.  <a href="https://sites.google.com/site/unclebobconsultingllc/">Robert C. Martin</a> describes this as each module having “a single reason to change”.</p>
<p>Coupling is a measure of how dependent different modules are on the internal workings of other modules. In a loosely coupled system, any module can be completely rewritten as long as it exposes the same public interface, without any other modules needing to change.  In a tightly coupled system, changing the internal details of one module may require changes in many other modules.</p>
<p>In the real world most systems are not purely orthogonal, and their modules are likely not 100% cohesive and uncoupled.  But striving for these goals is a good approximation of what many people mean when they talk about <em>separation of concerns</em>.</p>
<h3>Conways Law</h3>
<p><a href="http://amzn.to/2hNzQ0t">The Pragmatic Programmer</a> does touch on another application of orthogonality to software engineering:</p>
<blockquote>
<p>Have you noticed how some project teams are efficient, with everyone knowing what to do and contributing fully, while the members of other teams are constantly bickering and don’t seem able to get out of each other’s way?</p>
<p>Often this is an orthogonality issue. When teams are organized with lots of overlap, members are confused about responsibilities. Every change needs a meeting of the entire team, because any one of them might be affected.</p>
<p>How do you organize teams into groups with well-defined responsibilities and minimal overlap? There’s no simple answer. It depends partly on the project and your analysis of the areas of potential change. It also depends on the people you have available. Our preference is to start by separating infrastructure from application. Each major infrastructure component (database, communications interface, middleware layer, and so on) gets its own subteam. Each obvious division of application functionality is similarly divided. Then we look at the people we have (or plan to have) and adjust the groupings accordingly.</p>
<p>You can get an informal measure of the orthogonality of a project team’s structure. Simply see how many people need to be involved in discussing each change that is requested. The larger the number, the less orthogonal the group. Clearly, an orthogonal team is more efficient.</p>
<p><strong>— The Pragmatic Programmer</strong></p>
</blockquote>
<p>The idea is that teams work more efficiently when each can work in its own areas without having to be bogged down by using another group (or individuals) code, and only interacting with those modules through a well communicated interface.  This is also known as <a href="https://en.wikipedia.org/wiki/Conway's_law">Conway’s Law</a>, which is often used disparagingly but still stands as a true observation about real life code.</p>
<blockquote>
<p>organizations which design systems … are constrained to produce designs which are copies of the communication structures of these organizations</p>
<p><strong>— Conway’s Law</strong></p>
</blockquote>
<p>Although it usually isn’t phrased quite so explicitly, I believe Conway’s law is often related to what people mean when they discuss separation of concerns in front end development.</p>
<h3>Boundaries and Interfaces between CSS and JavaScript</h3>
<p>Let’s look at 2 examples of how CSS can be structured.  We’ll use a “page view counter” as our example. The element will show the number of users who have viewed the page, and respond to click events by showing a modal with the most popular pages on the site.
First, for a more traditional example, I’ll show a <a href="http://marionettejs.com/">Marionette</a> View, with separate CSS. For a more integrated example, I’ll use a React component.</p>
<h4>Marionette</h4>
<pre><code class="language-javascript">//view-counter.js

import Mn from 'backbone.marionette';
import template from './view-counter.hbs'
import { getPageViews, showModal } from '../util/page-views';

var ViewCounter = Mn.View.extend({

  template,

  className: 'page-view-counter',

  ui:  {
    'showPageViewsModal': '.show-modal-js',
  },

  events: {
    'click @ui.showPageViewsModal': 'showPageViewsModal',
  }

  templateContext() {
      return {
        pageViews: getPageViews(),
      };
  },

  showPageViewsModal() {
    showModal();
  }

});
</code></pre>
<pre><code class="language-hbs">{{!view-counter.hbs}}

&lt;span class=&quot;page-view-counter__title&quot;&gt; Page Views: &lt;/span&gt;
&lt;span class=&quot;page-view-counter__counter show-modal-js&quot;&gt; {{pageViews}} &lt;/span&gt;
</code></pre>
<pre><code class="language-css">//view-counter.css

.page-view-counter {
  display: flex;
}

.page-view-counter__title {
  font-weight: 700;
  padding: 3px;
}

.page-view-counter__counter {
  padding: 3px;
}
</code></pre>
<h4>React</h4>
<pre><code class="language-javascript">//view-counter.jsx
import React from 'react';
import { showModal } from '../util/page-views';

export const PageViewCounter = (props) =&gt; {
    return &lt;div style = {{display: 'flex'}}&gt;
      &lt;span style = {{
        fontWeight: 700,
        padding: '3px',
      }}&gt;
        Page Views:
      &lt;/span&gt;
      &lt;span style = {{padding: '3px'}}&gt;{this.props.pageViews}&lt;/span&gt;
    &lt;/div&gt;
}

</code></pre>
<p>The React and Marionette examples have set different module boundaries. In the Marionette example, we have defined 3 modules, split by code type.  Ignoring the leaky abstractions in the Marionette boundaries [^3], we can say we have 3 modules with clear singular purpose (styling, behavior,  structure) that use class names and  <code>templateContext</code> as interfaces.  The handlebars file exposes classes, which the CSS uses to style elements and the JavaScript code uses as attachment points for event handling.  The JavaScript view passes data to the template through templateContext.  In the React code we have defined a single module that exports a component as its only external interface. The module’s single purpose could be defined as “rendering a PageViewCounter”.</p>
<h3>How do we define module boundaries?</h3>
<p>If you’re excited to read which of the above examples is the <em>correct</em> module boundary definition, I’m sorry to disappoint you.  It turns out that module boundaries are more of an art than a science.  Let’s consider each of these examples by the criteria we laid out above.</p>
<p>The Marionette modules are <strong>cohesive</strong>.  Each module is single purpose, with a clear reason why it might change.  The React module is also cohesive, as it describes a single atomic component. However, it has more reasons it might change.  We might change that module because of a change in the look and feel of the site, because of a change in the expected behavior of the click event, or because we’re changing the text inside the component.</p>
<p>The Marionette modules are not quite <strong>decoupled</strong>.  While this CSS doesn’t nest selectors and we don’t have any explicit dependencies on the HTML structure, it is still written in a way that assumes <code>.page-view-counter__title</code> and <code>.page-view-counter__counter</code> will be direct children of <code>.page-view-counter</code>.  So changing the “internal details” of the Handlebars file by adding an extra element around those children would break the CSS. While the modules are not completely decoupled from each other, they don’t rely on any private details of other modules or global styles and can be used together as a reusable component.  The React module is similarly decoupled from the rest of the system, and as a single module faces no internal coupling issues.</p>
<p>Both components should be <strong>orthogonal</strong> from the rest of the system, even though the Marionette modules may be less orthogonal internally.  The question of how they meet a Conway’s law style of orthogonality depends on a team.  If your team has designers, and developers separately working on style/structure and behavior, the Marionette version may allow for more efficient division of labor, with communication centering on class based communication.  If you instead have a group of polyglot front end developers who implement mocks from designers across all 3 areas, the React version will instead present a simpler implementation that maps better to your team, with the focus on interfaces across different components.</p>
<p>In the end decisions like this are an exercise in understanding context and preferences.  What will make your team productive? You can accept the coupling of the first example in order to gain the benefits of small focused modules.  Or you can take the larger scope of the React component in exchange for keeping all information relevant to a component in one place.  Are you making single developers responsible for a set of components?  Or are they responsible for behavior generally, with design handled by someone else? Make the decisions that work for your project.</p>
<h3>More Resources</h3>
<ul>
<li><a href="http://amzn.to/2hNzQ0t">The Pragmatic Programmer</a> is a great book. Much of the vocabulary in this post comes from its Chapter 8, but the whole book is worth a read and is highly recommended.</li>
<li>CSS Tricks has a good look at the <a href="https://css-tricks.com/the-debate-around-do-we-even-need-css-anymore/">pros and cons of CSS in JS</a>.  I focused on theory here, but this is much more hands on about the practical concerns around this debate.</li>
</ul>
<p>[^1]: This is a bit of a generalization.  React provides an abstraction over HTML that replaces hand-written HTML, but doesn’t specify anything for CSS, CSS in JS solutions are simply popular in that community.  Vue and Angular both allow  CSS and HTML to share a file with JS, but CSS can still be handled separately.
[^2]: There are some distinctions about CSS in JS vs importing CSS into JS using webpack that I’m not really dealing with here.  This is a post about how to think about these decisions moreso than the specific options for bundling CSS and JS
[^3]: The root HTML element in any Marionette component is always defined implicitly in JavaScript, and Handlebars is an expressive templating language that can handle more than structure.</p>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
        <item>
            <title><![CDATA[2016 Roundup]]></title>
            <link>https://benmccormick.org/2016/12/31/2016-roundup/</link>
            <guid>https://benmccormick.org/2016/12/31/2016-roundup/</guid>
            <pubDate>Fri, 30 Dec 2016 02:15:00 GMT</pubDate>
            <content:encoded><![CDATA[<p>Thanks to all of you who have followed my blog this year! It was a busy year and I didn’t get as many posts out as years past, but you all have been as supportive as ever.  I’m excited about the things I’ve been able to do with the new site this month, and am looking forward to a great 2017.  But first, a look back.</p>
<h3>Most Read Posts of 2016</h3>
<p>I wrote 15 posts in 2016, down from my pace of 19 in 2015 and 25 in 2014.  Some of that was an unusually busy work year, and some of the time I normally put into the site went to the redesdign. I also sat on a few articles that didn’t turn out that great when actually written out.  But I made a good run at the end and hopefully will be writing more in 2017.  The most read posts from this site in 2016 were:</p>
<ol>
<li>
<p><a href="http://benmccormick.org/2016/01/11/the-most-interesting-atom-packages-ive-found-so-far/">The Most Interesting Atom Packages I’ve found so far</a> - I started using <a href="https://atom.io/">Atom</a> as my primary text editor late in 2015.  This was my roundup of the coolest and most unique plugins I had found for Atom at that point.</p>
</li>
<li>
<p><a href="http://benmccormick.org/2016/09/19/testing-with-jest-snapshots-first-impressions/">Testing with Jest Snapshots</a> - This was my review of <a href="https://facebook.github.io/jest/">Jest</a>’s snapshot testing feature.  I found it extremely useful for testing UI components.  I also wrote about Jest again <a href="http://benmccormick.org/2016/12/10/saving-time-with-jest/">this month</a>, transcribing a talk I gave at a local meetup on <a href="http://benmccormick.org/2016/12/10/saving-time-with-jest/">How Jest can save you time</a>.</p>
</li>
<li>
<p><a href="http://benmccormick.org/2016/01/08/reusable-code-patterns/">Reusable Code Patterns</a> - This article was a high level look at the ways you can approach sharing code for 2 different use cases.</p>
</li>
</ol>
<h4>Honorable Mention</h4>
<p><a href="http://benmccormick.org/2015/12/30/es6-patterns-converting-callbacks-to-promises/">ES6 Patterns: Converting Callbacks to Promises</a> - This article was technically written in 2015, but it was published during the last week of the year and thus wasn’t eligible to be included last year. However it has proven quite popular.  This was my attempt at a straightforward explanation of how to convert a callback based API to a Promise based one.</p>
<h3>Code I wrote in 2016</h3>
<p>Most of the code I wrote this year was for my work at Windsor Circle.  But I have spent some time getting this blog up and running, and anyone interested in what it takes to get a fully functioning blog running on <a href="https://github.com/gatsbyjs/gatsby">Gatsby</a> is welcome to take a look at the <a href="https://github.com/benmccormick/benmccormickorg">github repo</a>.</p>
<h3>Languages, Libraries, and Technologies I started using in 2016</h3>
<ul>
<li>
<p><a href="https://facebook.github.io/jest/">Jest</a> is a JavaScript testing library that I started using this year. It’s fantastic, and I’ve had the opportunity to <a href="http://benmccormick.org/2016/09/19/testing-with-jest-snapshots-first-impressions/">write</a> and <a href="http://benmccormick.org/2016/12/10/saving-time-with-jest/">speak</a> about it a few times already.</p>
</li>
<li>
<p><a href="https://github.com/gatsbyjs/gatsby">Gatsbyjs</a> now powers this blog. Gatsby is a ReactJS based static site generator, and it has been a pleasure to work with.</p>
</li>
<li>
<p>My team started using <a href="https://www.docker.com/">Docker</a> this year.  It’s been a mixed bag for me personally, but I love the idea of what it provides</p>
</li>
</ul>
<h3>Languages, Libraries, and Technologies I stopped using in 2016</h3>
<ul>
<li>Despite my affection for <a href="http://marionettejs.com/">Marionette</a>, I’m no longer actively using it other than in some legacy code for my work application</li>
</ul>
<h3>Languages and Libraries I used (more or less) every day in 2016</h3>
<p>JavaScript (ES6), Python, React, PostgreSQL, Backbone, lodash</p>
<h3>Languages and Libraries I want to try in 2017</h3>
<p>RxJS, Flow, VueJS, <a href="https://github.com/FormidableLabs/victory">Victory</a>, Pandas and other python data analysis libraries, Rust</p>
<h3>Blogs I started following in 2016</h3>
<p>Nothing new this year,</p>
<h3>Blogs I read every post from in 2016</h3>
<p>Rands In Repose, Stratechery, Daring Fireball,  <a href="http://Marco.org">Marco.org</a>, <a href="http://rauchg.com">rauchg.com</a>, <a href="http://purposedworking.com">purposedworking.com</a></p>
<h3>Podcasts I started listening to in 2016</h3>
<ul>
<li><a href="http://www.npr.org/podcasts/510310/npr-politics-podcast">NPR Politics</a> - Approachable and fun while still being informative, one of the best ways to follow this years election.</li>
</ul>
<p><a href="http://www.npr.org/podcasts/510313/how-i-built-this">How I Built This</a> - This has been a great new podcast on entrepreneurship</p>
<h3>Software I started using in 2016</h3>
<ul>
<li>
<p><a href="http://inbox.google.com">Google Inbox</a> + <a href="http://airmailapp.com/">Airmail</a> for email: I’m not sure I’m ever going to be happy with an email client, but I’m currently using the combo of Google Inbox on iOS and Airmail on MacOS.  Post <a href="https://www.mailboxapp.com/">Mailbox</a>, Inbox is my favorite iOS mail app.  On desktop though I like to have universal inbox and tight integration with the rest of the operating system, so I use Airmail, which is less bad than the rest of the MacOS mail clients I’ve tried</p>
</li>
<li>
<p><a href="http://copiedapp.com/">Copied</a>: Copied is a clipboard manager for MacOS (and sort of iOS).  It’s been great to be able to keep multiple things in the clipboard at once, and be able to go back and get something if I blow it away.  I’m not a power user.  I haven’t really figured out a reason to use their lists features, or their iOS client, but it has been great for the limited things I use it for.</p>
</li>
<li>
<p><a href="https://caskroom.github.io/">Homebrew Cask</a>: I’ve used homebrew for a while.  But being able to install GUI apps as easily as command line apps has been pretty amazing.  If you are on OSX and don’t use homebrew to install pretty much everything, you’re missing out.  Of course the real effect is that it makes me dread and hate the Mac App Store even more.</p>
</li>
<li>
<p><a href="http://www.nytimes.com/services/mobile/">The New York Times App</a>: Ok this is a bit of a cheat since this is more about content than software, but if you’re out of touch on what is going on in the world, there’s never been a better time to support a good source of news and reporting, whichever outlet is your preference.</p>
</li>
</ul>
<h3>Software I stopped using in 2016</h3>
<p>Nothing I’m aware of, though I am currently checking out <a href="http://www.bear-writer.com/">Bear</a> and <a href="https://itunes.apple.com/us/app/annotate-capture-and-share/id918207447?mt=12">Annotate</a> as potential replacements for Evernote and Skitch.</p>
<h3>Software I used (nearly) every day in 2016</h3>
<p>MacOS/iOS, Google Search, Chrome/Safari, Google Inbox/Airmail, Twitter/Tweetbot, Feedbin/Reeder, Instapaper, iMessage, Slack, Trello, 1Password, Atom/Vim, iTerm, Fish Shell, tmux, Bitbucket, Fantastical, Spotify, Evernote, Skitch, Dash</p>
]]></content:encoded>
            <author>
                <name>Ben McCormick</name>
                <email>ben@benmccormick.org</email>
                <link>http://benmccormick.org</link>
            </author>
        </item>
    </channel>
</rss>